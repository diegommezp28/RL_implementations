{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nvcc4jupyter\n",
      "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: nvcc4jupyter\n",
      "Successfully installed nvcc4jupyter-1.2.1\n",
      "Source files will be saved in \"C:\\Users\\diego\\AppData\\Local\\Temp\\tmpp9reof93\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\diego\\anaconda3\\envs\\torch_last\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"C:\\Users\\diego\\AppData\\Local\\Temp\\tmphj81mhtd\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from block: 1, thread: 0\n",
      "Hello from block: 1, thread: 1\n",
      "Hello from block: 0, thread: 0\n",
      "Hello from block: 0, thread: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void hello(){\n",
    "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    hello<<<2, 2>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "Device Number: 0\n",
      "  Device name: NVIDIA GeForce RTX 2060\n",
      "  Memory Clock Rate (MHz): 6836\n",
      "  Memory Bus Width (bits): 192\n",
      "  Peak Memory Bandwidth (GB/s): 336.0\n",
      "  Total global memory (Gbytes) 6.0\n",
      "  Shared memory per block (Kbytes) 48.0\n",
      "  minor-major: 5-7\n",
      "  Warp-size: 32\n",
      "  Concurrent kernels: yes\n",
      "  Concurrent computation/communication: yes\n",
      "\n",
      "no error\n",
      "no error\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#\n",
    "#include <stdio.h>\n",
    "#include <string>\n",
    "#include <iostream>\n",
    "\n",
    "int main() {\n",
    "\n",
    "  int nDevices;\n",
    "  cudaGetDeviceCount(&nDevices);\n",
    "  \n",
    "  printf(\"Number of devices: %d\\n\", nDevices);\n",
    "  \n",
    "  for (int i = 0; i < nDevices; i++) {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, i);\n",
    "    printf(\"Device Number: %d\\n\", i);\n",
    "    printf(\"  Device name: %s\\n\", prop.name);\n",
    "    printf(\"  Memory Clock Rate (MHz): %d\\n\",\n",
    "           prop.memoryClockRate/1024);\n",
    "    printf(\"  Memory Bus Width (bits): %d\\n\",\n",
    "           prop.memoryBusWidth);\n",
    "    printf(\"  Peak Memory Bandwidth (GB/s): %.1f\\n\",\n",
    "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
    "    printf(\"  Total global memory (Gbytes) %.1f\\n\",(float)(prop.totalGlobalMem)/1024.0/1024.0/1024.0);\n",
    "    printf(\"  Shared memory per block (Kbytes) %.1f\\n\",(float)(prop.sharedMemPerBlock)/1024.0);\n",
    "    printf(\"  minor-major: %d-%d\\n\", prop.minor, prop.major);\n",
    "    printf(\"  Warp-size: %d\\n\", prop.warpSize);\n",
    "    printf(\"  Concurrent kernels: %s\\n\", prop.concurrentKernels ? \"yes\" : \"no\");\n",
    "    printf(\"  Concurrent computation/communication: %s\\n\\n\",prop.deviceOverlap ? \"yes\" : \"no\");\n",
    "  }\n",
    "\n",
    "  cudaError_t cuda_error = cudaGetLastError();\n",
    "  std::cout << cudaGetErrorString(cuda_error) << \"\\n\" ;\n",
    "  std::cout << cudaGetErrorString(cudaSuccess) ;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "no error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "\n",
    "// Lets try to break things\n",
    "\n",
    "int main(){\n",
    "    char* var = \"Hello\";        // var points to a string literal \"Hello\"\n",
    "    char* nul_char = (var + 5); // nul_char points to the null terminator character '\\0' in the string \"Hello\"\n",
    "    //*nul_char = 'a';            // Attempting to modify the null terminator character ('\\0') to 'a'\n",
    "    cout << var << '\\n';    \n",
    "\n",
    "    cudaError_t cuda_error = cudaGetLastError();\n",
    "    cout << cudaGetErrorString(cuda_error) << \"\\n\" ;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Wolrd!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "\n",
    "auto main() -> int {\n",
    "    cout << \"Hello Wolrd!\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a simple CUDA kernel that gives the sum of maximum element of 2 vectors and profile it for:\n",
    "\n",
    "* Execution on 1 thread and 1 block\n",
    "* Execution on all threads of 1 block\n",
    "* Execution on all threads of n blocks. Deciding n is upto you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 2.09715e+06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <iostream>\n",
    "#include <algorithm>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cmath>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void sum_of_maximums(float *a, float *b, int size_a, int size_b, float *result){\n",
    "\n",
    "\n",
    "    float maximum_a = a[0];\n",
    "    float maximum_b = b[0];\n",
    "\n",
    "    for(int i = 0; i < size_a; i++){\n",
    "        maximum_a = fmax(maximum_a, a[i]);\n",
    "    }\n",
    "\n",
    "    for(int i = 0; i < size_b; i++){\n",
    "        maximum_b = fmax(maximum_b, b[i]);\n",
    "    }\n",
    "\n",
    "    *result = maximum_a + maximum_b;\n",
    "\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int N = 1 << 20;\n",
    "    float *a, *b;\n",
    "\n",
    "    float *result;\n",
    "\n",
    "    cudaMallocManaged(&a, N*sizeof(float));\n",
    "    cudaMallocManaged(&b, N*sizeof(float));\n",
    "    cudaMallocManaged(&result, sizeof(float));\n",
    "\n",
    "    for(int i = 0; i < N; i++){\n",
    "        a[i] = i;\n",
    "        b[i] = i;\n",
    "    }\n",
    "\n",
    "    sum_of_maximums<<<1, 1>>>(a, b, N, N, result);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    std::cout << \"Result: \" << *result << \"\\n\";\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cudaFree(a);\n",
    "    cudaFree(b);\n",
    "    cudaFree(result);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "__global__ void add_basic(float *x, int n)\n",
    "{\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        x[i] = x[i] * 2;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    // COMPLETE THIS\n",
    "    int N = 1000000;\n",
    "\n",
    "    float *x;\n",
    "\n",
    "    cudaMallocManaged(&x, N * sizeof(float));\n",
    "    for (int i = 0; i < N; i++)\n",
    "    {\n",
    "        x[i] = 1.0f;\n",
    "    }\n",
    "\n",
    "    add_basic <<< 32, 32 >>> (x, N);\n",
    "\n",
    "    // Wait for GPU to finish before accessing on host\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Check for errors (all values should be 2.0f)\n",
    "    float maxError = 0.0f;\n",
    "    for (int i = 0; i < N; i++)\n",
    "    {\n",
    "        maxError = fmax(maxError, fabs(x[i] - 2.0f));\n",
    "    }\n",
    "    std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "    // Free memory\n",
    "    cudaFree(x);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Maximum: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <iostream>\n",
    "#include <algorithm>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(){\n",
    "    printf(\"Hello World!\\n\");\n",
    "\n",
    "    int N = 10;\n",
    "\n",
    "    float *a = new float[N];\n",
    "\n",
    "    for(int i = 0; i < N; i++){\n",
    "        a[i] =  i;\n",
    "    }\n",
    "\n",
    "    float maximum = *std::max_element(a, a+N);\n",
    "\n",
    "    std::cout << \"Maximum: \" << maximum << \"\\n\";\n",
    "\n",
    "    delete[] a;\n",
    "\n",
    "\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Maximum: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <iostream>\n",
    "#include <algorithm>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(){\n",
    "    printf(\"Hello World!\\n\");\n",
    "\n",
    "    int N = 10;\n",
    "\n",
    "    float *a = static_cast<float*>(malloc(N*sizeof(float)));\n",
    "\n",
    "    for(int i = 0; i < N; i++){\n",
    "        a[i] =  i;\n",
    "    }\n",
    "\n",
    "    float maximum = *std::max_element(a, a+N);\n",
    "\n",
    "    std::cout << \"Maximum: \" << maximum << \"\\n\";\n",
    "\n",
    "    free(a);    \n",
    "\n",
    "\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "#include <algorithm>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "\n",
    "auto main() -> int {\n",
    "\n",
    "    const int N = 10;\n",
    "\n",
    "    float a[N];\n",
    "\n",
    "    for(int i = 0; i < N; i++){\n",
    "        a[i] = i;\n",
    "    }\n",
    "\n",
    "    float maximum = *std::max_element(a, a+N);\n",
    "    cout << \"Maximum: \" << maximum << \"\\n\";\n",
    "\n",
    "    //delete[] a;\n",
    "\n",
    "    return 0;\n",
    "\n",
    "\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
